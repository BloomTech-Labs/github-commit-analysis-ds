{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37464bitbasecondaa825d1717f2d413ba37c2252512fd943",
   "display_name": "Python 3.7.4 64-bit ('base': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from flask import jsonify\n",
    "import numpy as np\n",
    "import requests\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>additions</th>\n      <th>author</th>\n      <th>bodyText</th>\n      <th>changedFiles</th>\n      <th>closedAt</th>\n      <th>comments</th>\n      <th>commits</th>\n      <th>createdAt</th>\n      <th>deletions</th>\n      <th>id</th>\n      <th>participants</th>\n      <th>reactions</th>\n      <th>state</th>\n      <th>title</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>153</td>\n      <td>{'login': 'agramfort'}</td>\n      <td>NaN</td>\n      <td>7</td>\n      <td>2010-09-02T14:10:16Z</td>\n      <td>{'totalCount': 2}</td>\n      <td>{'totalCount': 9}</td>\n      <td>2010-09-01T13:06:00Z</td>\n      <td>77</td>\n      <td>MDExOlB1bGxSZXF1ZXN0NjU0</td>\n      <td>{'totalCount': 3}</td>\n      <td>{'totalCount': 0}</td>\n      <td>MERGED</td>\n      <td>more on LARS (we're getting there)</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>51</td>\n      <td>{'login': 'agramfort'}</td>\n      <td>this is just a draft but maybe a good start to...</td>\n      <td>2</td>\n      <td>2010-10-23T15:44:33Z</td>\n      <td>{'totalCount': 1}</td>\n      <td>{'totalCount': 1}</td>\n      <td>2010-09-02T17:13:55Z</td>\n      <td>0</td>\n      <td>MDExOlB1bGxSZXF1ZXN0MTEzOQ==</td>\n      <td>{'totalCount': 4}</td>\n      <td>{'totalCount': 0}</td>\n      <td>CLOSED</td>\n      <td>Scaling and preprocessing</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>6631</td>\n      <td>{'login': 'ogrisel'}</td>\n      <td>Implementation of CD for elastic net on scipy....</td>\n      <td>13</td>\n      <td>2010-09-14T13:00:43Z</td>\n      <td>{'totalCount': 2}</td>\n      <td>{'totalCount': 25}</td>\n      <td>2010-09-09T16:03:53Z</td>\n      <td>9</td>\n      <td>MDExOlB1bGxSZXF1ZXN0MzEzNg==</td>\n      <td>{'totalCount': 1}</td>\n      <td>{'totalCount': 0}</td>\n      <td>MERGED</td>\n      <td>Issue 77 sparse cd</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>105</td>\n      <td>{'login': 'GaelVaroquaux'}</td>\n      <td>Code review: I am interested in suggestions on...</td>\n      <td>6</td>\n      <td>2010-09-16T21:39:45Z</td>\n      <td>{'totalCount': 1}</td>\n      <td>{'totalCount': 3}</td>\n      <td>2010-09-15T15:48:15Z</td>\n      <td>27</td>\n      <td>MDExOlB1bGxSZXF1ZXN0NTA0Nw==</td>\n      <td>{'totalCount': 2}</td>\n      <td>{'totalCount': 0}</td>\n      <td>MERGED</td>\n      <td>Work on cross val and pipelines.</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>12636</td>\n      <td>{'login': 'ogrisel'}</td>\n      <td>NaN</td>\n      <td>14</td>\n      <td>2010-10-25T00:27:02Z</td>\n      <td>{'totalCount': 1}</td>\n      <td>{'totalCount': 17}</td>\n      <td>2010-10-24T15:29:53Z</td>\n      <td>8</td>\n      <td>MDExOlB1bGxSZXF1ZXN0MTk0NjY=</td>\n      <td>{'totalCount': 2}</td>\n      <td>{'totalCount': 0}</td>\n      <td>CLOSED</td>\n      <td>Some cleanups</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "   additions                      author  \\\n0        153      {'login': 'agramfort'}   \n1         51      {'login': 'agramfort'}   \n2       6631        {'login': 'ogrisel'}   \n3        105  {'login': 'GaelVaroquaux'}   \n4      12636        {'login': 'ogrisel'}   \n\n                                            bodyText  changedFiles  \\\n0                                                NaN             7   \n1  this is just a draft but maybe a good start to...             2   \n2  Implementation of CD for elastic net on scipy....            13   \n3  Code review: I am interested in suggestions on...             6   \n4                                                NaN            14   \n\n               closedAt           comments             commits  \\\n0  2010-09-02T14:10:16Z  {'totalCount': 2}   {'totalCount': 9}   \n1  2010-10-23T15:44:33Z  {'totalCount': 1}   {'totalCount': 1}   \n2  2010-09-14T13:00:43Z  {'totalCount': 2}  {'totalCount': 25}   \n3  2010-09-16T21:39:45Z  {'totalCount': 1}   {'totalCount': 3}   \n4  2010-10-25T00:27:02Z  {'totalCount': 1}  {'totalCount': 17}   \n\n              createdAt  deletions                            id  \\\n0  2010-09-01T13:06:00Z         77      MDExOlB1bGxSZXF1ZXN0NjU0   \n1  2010-09-02T17:13:55Z          0  MDExOlB1bGxSZXF1ZXN0MTEzOQ==   \n2  2010-09-09T16:03:53Z          9  MDExOlB1bGxSZXF1ZXN0MzEzNg==   \n3  2010-09-15T15:48:15Z         27  MDExOlB1bGxSZXF1ZXN0NTA0Nw==   \n4  2010-10-24T15:29:53Z          8  MDExOlB1bGxSZXF1ZXN0MTk0NjY=   \n\n        participants          reactions   state  \\\n0  {'totalCount': 3}  {'totalCount': 0}  MERGED   \n1  {'totalCount': 4}  {'totalCount': 0}  CLOSED   \n2  {'totalCount': 1}  {'totalCount': 0}  MERGED   \n3  {'totalCount': 2}  {'totalCount': 0}  MERGED   \n4  {'totalCount': 2}  {'totalCount': 0}  CLOSED   \n\n                                title  \n0  more on LARS (we're getting there)  \n1           Scaling and preprocessing  \n2                  Issue 77 sparse cd  \n3    Work on cross val and pipelines.  \n4                       Some cleanups  "
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('scikit-learn-prs.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanCounts(df):\n",
    "    '''Remove {totalCount: } from the counts columns to the data is cleaner\n",
    "       and {login: } from author column'''\n",
    "    df['author'] = df['author'].str.replace(\"{'login':\", '')\n",
    "    for i in df.columns:\n",
    "        if df[i].dtypes == 'O':\n",
    "            df[i] = df[i].str.replace(\"{'totalCount':\", '')\n",
    "            df[i] = df[i].str.replace('}', '')\n",
    "    return df\n",
    "\n",
    "def findTimeToClose(df):\n",
    "    '''Generate feature showing the time it take from pull request opening\n",
    "       to pull request being either merged or closed.\n",
    "       Account for open prs by using current time for closedAt'''\n",
    "    df['closedAt'] = pd.to_datetime(df['closedAt'], infer_datetime_format=True)\n",
    "    df['createdAt'] = pd.to_datetime(df['createdAt'], infer_datetime_format=True)\n",
    "    df['timeToClosure'] = df['closedAt'] - df['createdAt']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'str' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-4d3c0320a6f0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mdays\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTimestamp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'createdAt'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mdays\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'closedAt'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'createdAt'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'str' and 'str'"
     ]
    }
   ],
   "source": [
    "days = []\n",
    "for i in df.index:\n",
    "    if pd.isna(df['closedAt'][i]):\n",
    "        days.append(pd.Timestamp.now() - df['createdAt'][i])\n",
    "    else:\n",
    "        days.append(df['closedAt'][i] - df['createdAt'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['time_to_closure2'] = pd.Series(days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>additions</th>\n      <th>author</th>\n      <th>bodyText</th>\n      <th>changedFiles</th>\n      <th>closedAt</th>\n      <th>comments</th>\n      <th>commits</th>\n      <th>createdAt</th>\n      <th>deletions</th>\n      <th>id</th>\n      <th>participants</th>\n      <th>reactions</th>\n      <th>state</th>\n      <th>title</th>\n      <th>time_to_closure</th>\n      <th>time_to_closure2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>153</td>\n      <td>'agramfort'</td>\n      <td>NaN</td>\n      <td>7</td>\n      <td>2010-09-02 14:10:16</td>\n      <td>2</td>\n      <td>9</td>\n      <td>2010-09-01 13:06:00</td>\n      <td>77</td>\n      <td>MDExOlB1bGxSZXF1ZXN0NjU0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>MERGED</td>\n      <td>more on LARS (we're getting there)</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>51</td>\n      <td>'agramfort'</td>\n      <td>this is just a draft but maybe a good start to...</td>\n      <td>2</td>\n      <td>2010-10-23 15:44:33</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2010-09-02 17:13:55</td>\n      <td>0</td>\n      <td>MDExOlB1bGxSZXF1ZXN0MTEzOQ==</td>\n      <td>4</td>\n      <td>0</td>\n      <td>CLOSED</td>\n      <td>Scaling and preprocessing</td>\n      <td>50.0</td>\n      <td>50</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>6631</td>\n      <td>'ogrisel'</td>\n      <td>Implementation of CD for elastic net on scipy....</td>\n      <td>13</td>\n      <td>2010-09-14 13:00:43</td>\n      <td>2</td>\n      <td>25</td>\n      <td>2010-09-09 16:03:53</td>\n      <td>9</td>\n      <td>MDExOlB1bGxSZXF1ZXN0MzEzNg==</td>\n      <td>1</td>\n      <td>0</td>\n      <td>MERGED</td>\n      <td>Issue 77 sparse cd</td>\n      <td>4.0</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>105</td>\n      <td>'GaelVaroquaux'</td>\n      <td>Code review: I am interested in suggestions on...</td>\n      <td>6</td>\n      <td>2010-09-16 21:39:45</td>\n      <td>1</td>\n      <td>3</td>\n      <td>2010-09-15 15:48:15</td>\n      <td>27</td>\n      <td>MDExOlB1bGxSZXF1ZXN0NTA0Nw==</td>\n      <td>2</td>\n      <td>0</td>\n      <td>MERGED</td>\n      <td>Work on cross val and pipelines.</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>12636</td>\n      <td>'ogrisel'</td>\n      <td>NaN</td>\n      <td>14</td>\n      <td>2010-10-25 00:27:02</td>\n      <td>1</td>\n      <td>17</td>\n      <td>2010-10-24 15:29:53</td>\n      <td>8</td>\n      <td>MDExOlB1bGxSZXF1ZXN0MTk0NjY=</td>\n      <td>2</td>\n      <td>0</td>\n      <td>CLOSED</td>\n      <td>Some cleanups</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "   additions            author  \\\n0        153       'agramfort'   \n1         51       'agramfort'   \n2       6631         'ogrisel'   \n3        105   'GaelVaroquaux'   \n4      12636         'ogrisel'   \n\n                                            bodyText  changedFiles  \\\n0                                                NaN             7   \n1  this is just a draft but maybe a good start to...             2   \n2  Implementation of CD for elastic net on scipy....            13   \n3  Code review: I am interested in suggestions on...             6   \n4                                                NaN            14   \n\n             closedAt comments commits           createdAt  deletions  \\\n0 2010-09-02 14:10:16        2       9 2010-09-01 13:06:00         77   \n1 2010-10-23 15:44:33        1       1 2010-09-02 17:13:55          0   \n2 2010-09-14 13:00:43        2      25 2010-09-09 16:03:53          9   \n3 2010-09-16 21:39:45        1       3 2010-09-15 15:48:15         27   \n4 2010-10-25 00:27:02        1      17 2010-10-24 15:29:53          8   \n\n                             id participants reactions   state  \\\n0      MDExOlB1bGxSZXF1ZXN0NjU0            3         0  MERGED   \n1  MDExOlB1bGxSZXF1ZXN0MTEzOQ==            4         0  CLOSED   \n2  MDExOlB1bGxSZXF1ZXN0MzEzNg==            1         0  MERGED   \n3  MDExOlB1bGxSZXF1ZXN0NTA0Nw==            2         0  MERGED   \n4  MDExOlB1bGxSZXF1ZXN0MTk0NjY=            2         0  CLOSED   \n\n                                title  time_to_closure  time_to_closure2  \n0  more on LARS (we're getting there)              1.0                 1  \n1           Scaling and preprocessing             50.0                50  \n2                  Issue 77 sparse cd              4.0                 4  \n3    Work on cross val and pipelines.              1.0                 1  \n4                       Some cleanups              0.0                 0  "
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['time_to_closure2'] = df['time_to_closure2'].dt.days\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>additions</th>\n      <th>author</th>\n      <th>bodyText</th>\n      <th>changedFiles</th>\n      <th>closedAt</th>\n      <th>comments</th>\n      <th>commits</th>\n      <th>createdAt</th>\n      <th>deletions</th>\n      <th>id</th>\n      <th>participants</th>\n      <th>reactions</th>\n      <th>state</th>\n      <th>title</th>\n      <th>timeToClosure</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>153</td>\n      <td>'agramfort'</td>\n      <td>NaN</td>\n      <td>7</td>\n      <td>2010-09-02 14:10:16</td>\n      <td>2</td>\n      <td>9</td>\n      <td>2010-09-01 13:06:00</td>\n      <td>77</td>\n      <td>MDExOlB1bGxSZXF1ZXN0NjU0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>MERGED</td>\n      <td>more on LARS (we're getting there)</td>\n      <td>1 days 01:04:16</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>51</td>\n      <td>'agramfort'</td>\n      <td>this is just a draft but maybe a good start to...</td>\n      <td>2</td>\n      <td>2010-10-23 15:44:33</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2010-09-02 17:13:55</td>\n      <td>0</td>\n      <td>MDExOlB1bGxSZXF1ZXN0MTEzOQ==</td>\n      <td>4</td>\n      <td>0</td>\n      <td>CLOSED</td>\n      <td>Scaling and preprocessing</td>\n      <td>50 days 22:30:38</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>6631</td>\n      <td>'ogrisel'</td>\n      <td>Implementation of CD for elastic net on scipy....</td>\n      <td>13</td>\n      <td>2010-09-14 13:00:43</td>\n      <td>2</td>\n      <td>25</td>\n      <td>2010-09-09 16:03:53</td>\n      <td>9</td>\n      <td>MDExOlB1bGxSZXF1ZXN0MzEzNg==</td>\n      <td>1</td>\n      <td>0</td>\n      <td>MERGED</td>\n      <td>Issue 77 sparse cd</td>\n      <td>4 days 20:56:50</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>105</td>\n      <td>'GaelVaroquaux'</td>\n      <td>Code review: I am interested in suggestions on...</td>\n      <td>6</td>\n      <td>2010-09-16 21:39:45</td>\n      <td>1</td>\n      <td>3</td>\n      <td>2010-09-15 15:48:15</td>\n      <td>27</td>\n      <td>MDExOlB1bGxSZXF1ZXN0NTA0Nw==</td>\n      <td>2</td>\n      <td>0</td>\n      <td>MERGED</td>\n      <td>Work on cross val and pipelines.</td>\n      <td>1 days 05:51:30</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>12636</td>\n      <td>'ogrisel'</td>\n      <td>NaN</td>\n      <td>14</td>\n      <td>2010-10-25 00:27:02</td>\n      <td>1</td>\n      <td>17</td>\n      <td>2010-10-24 15:29:53</td>\n      <td>8</td>\n      <td>MDExOlB1bGxSZXF1ZXN0MTk0NjY=</td>\n      <td>2</td>\n      <td>0</td>\n      <td>CLOSED</td>\n      <td>Some cleanups</td>\n      <td>0 days 08:57:09</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "   additions            author  \\\n0        153       'agramfort'   \n1         51       'agramfort'   \n2       6631         'ogrisel'   \n3        105   'GaelVaroquaux'   \n4      12636         'ogrisel'   \n\n                                            bodyText  changedFiles  \\\n0                                                NaN             7   \n1  this is just a draft but maybe a good start to...             2   \n2  Implementation of CD for elastic net on scipy....            13   \n3  Code review: I am interested in suggestions on...             6   \n4                                                NaN            14   \n\n             closedAt comments commits           createdAt  deletions  \\\n0 2010-09-02 14:10:16        2       9 2010-09-01 13:06:00         77   \n1 2010-10-23 15:44:33        1       1 2010-09-02 17:13:55          0   \n2 2010-09-14 13:00:43        2      25 2010-09-09 16:03:53          9   \n3 2010-09-16 21:39:45        1       3 2010-09-15 15:48:15         27   \n4 2010-10-25 00:27:02        1      17 2010-10-24 15:29:53          8   \n\n                             id participants reactions   state  \\\n0      MDExOlB1bGxSZXF1ZXN0NjU0            3         0  MERGED   \n1  MDExOlB1bGxSZXF1ZXN0MTEzOQ==            4         0  CLOSED   \n2  MDExOlB1bGxSZXF1ZXN0MzEzNg==            1         0  MERGED   \n3  MDExOlB1bGxSZXF1ZXN0NTA0Nw==            2         0  MERGED   \n4  MDExOlB1bGxSZXF1ZXN0MTk0NjY=            2         0  CLOSED   \n\n                                title    timeToClosure  \n0  more on LARS (we're getting there)  1 days 01:04:16  \n1           Scaling and preprocessing 50 days 22:30:38  \n2                  Issue 77 sparse cd  4 days 20:56:50  \n3    Work on cross val and pipelines.  1 days 05:51:30  \n4                       Some cleanups  0 days 08:57:09  "
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = cleanCounts(df)\n",
    "df = findTimeToClose(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>additions</th>\n      <th>author</th>\n      <th>bodyText</th>\n      <th>changedFiles</th>\n      <th>closedAt</th>\n      <th>comments</th>\n      <th>commits</th>\n      <th>createdAt</th>\n      <th>deletions</th>\n      <th>id</th>\n      <th>participants</th>\n      <th>reactions</th>\n      <th>state</th>\n      <th>title</th>\n      <th>timeToClosure</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>9336</td>\n      <td>38</td>\n      <td>'glemaitre'</td>\n      <td>similar to #16500 but for plot_precision_recal...</td>\n      <td>3</td>\n      <td>NaT</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2020-02-20 22:11:41</td>\n      <td>5</td>\n      <td>MDExOlB1bGxSZXF1ZXN0Mzc4MDAxMDQw</td>\n      <td>1</td>\n      <td>0</td>\n      <td>OPEN</td>\n      <td>BUG ensure that name is properly stored in the...</td>\n      <td>NaT</td>\n    </tr>\n    <tr>\n      <td>9337</td>\n      <td>164</td>\n      <td>'rth'</td>\n      <td>Continues and closes #15015\\nThis merges the c...</td>\n      <td>10</td>\n      <td>NaT</td>\n      <td>1</td>\n      <td>10</td>\n      <td>2020-02-20 23:14:09</td>\n      <td>15</td>\n      <td>MDExOlB1bGxSZXF1ZXN0Mzc4MDI0MDQ0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>OPEN</td>\n      <td>Common check for sample weight invariance with...</td>\n      <td>NaT</td>\n    </tr>\n    <tr>\n      <td>9338</td>\n      <td>68</td>\n      <td>'thomasjpfan'</td>\n      <td>Reference Issues/PRs\\n\\nResolves #16498\\nWhat ...</td>\n      <td>3</td>\n      <td>NaT</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2020-02-21 00:12:40</td>\n      <td>0</td>\n      <td>MDExOlB1bGxSZXF1ZXN0Mzc4MDQxMjQz</td>\n      <td>1</td>\n      <td>1</td>\n      <td>OPEN</td>\n      <td>ENH Adds pandas IntegerArray support to check_...</td>\n      <td>NaT</td>\n    </tr>\n    <tr>\n      <td>9339</td>\n      <td>2</td>\n      <td>'thomasjpfan'</td>\n      <td>Reference Issues/PRs\\n\\nFixes #16506\\nWhat doe...</td>\n      <td>1</td>\n      <td>NaT</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2020-02-21 02:26:00</td>\n      <td>1</td>\n      <td>MDExOlB1bGxSZXF1ZXN0Mzc4MDcxODQ2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>OPEN</td>\n      <td>TST Sets random state in test_csr_row_norms</td>\n      <td>NaT</td>\n    </tr>\n    <tr>\n      <td>9340</td>\n      <td>41</td>\n      <td>'thomasjpfan'</td>\n      <td>Reference Issues/PRs\\n\\nContinues #16502\\nWhat...</td>\n      <td>3</td>\n      <td>NaT</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2020-02-21 03:08:12</td>\n      <td>8</td>\n      <td>MDExOlB1bGxSZXF1ZXN0Mzc4MDgwNjIz</td>\n      <td>1</td>\n      <td>0</td>\n      <td>OPEN</td>\n      <td>TST Checks can now skip test based on estimato...</td>\n      <td>NaT</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "      additions          author  \\\n9336         38     'glemaitre'   \n9337        164           'rth'   \n9338         68   'thomasjpfan'   \n9339          2   'thomasjpfan'   \n9340         41   'thomasjpfan'   \n\n                                               bodyText  changedFiles  \\\n9336  similar to #16500 but for plot_precision_recal...             3   \n9337  Continues and closes #15015\\nThis merges the c...            10   \n9338  Reference Issues/PRs\\n\\nResolves #16498\\nWhat ...             3   \n9339  Reference Issues/PRs\\n\\nFixes #16506\\nWhat doe...             1   \n9340  Reference Issues/PRs\\n\\nContinues #16502\\nWhat...             3   \n\n     closedAt comments commits           createdAt  deletions  \\\n9336      NaT        1       2 2020-02-20 22:11:41          5   \n9337      NaT        1      10 2020-02-20 23:14:09         15   \n9338      NaT        0       2 2020-02-21 00:12:40          0   \n9339      NaT        0       1 2020-02-21 02:26:00          1   \n9340      NaT        0       2 2020-02-21 03:08:12          8   \n\n                                    id participants reactions state  \\\n9336  MDExOlB1bGxSZXF1ZXN0Mzc4MDAxMDQw            1         0  OPEN   \n9337  MDExOlB1bGxSZXF1ZXN0Mzc4MDI0MDQ0            3         0  OPEN   \n9338  MDExOlB1bGxSZXF1ZXN0Mzc4MDQxMjQz            1         1  OPEN   \n9339  MDExOlB1bGxSZXF1ZXN0Mzc4MDcxODQ2            1         0  OPEN   \n9340  MDExOlB1bGxSZXF1ZXN0Mzc4MDgwNjIz            1         0  OPEN   \n\n                                                  title timeToClosure  \n9336  BUG ensure that name is properly stored in the...           NaT  \n9337  Common check for sample weight invariance with...           NaT  \n9338  ENH Adds pandas IntegerArray support to check_...           NaT  \n9339        TST Sets random state in test_csr_row_norms           NaT  \n9340  TST Checks can now skip test based on estimato...           NaT  "
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'time_to_closure'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2896\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2897\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2898\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'time_to_closure'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-e226ed72f067>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'time_to_closure'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'time_to_closure'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdays\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2978\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2979\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2980\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2981\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2982\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2897\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2898\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2899\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2900\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2901\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'time_to_closure'"
     ]
    }
   ],
   "source": [
    "df['time_to_closure'] = df['time_to_closure'].dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>additions</th>\n      <th>author</th>\n      <th>bodyText</th>\n      <th>changedFiles</th>\n      <th>closedAt</th>\n      <th>comments</th>\n      <th>commits</th>\n      <th>createdAt</th>\n      <th>deletions</th>\n      <th>id</th>\n      <th>participants</th>\n      <th>reactions</th>\n      <th>state</th>\n      <th>title</th>\n      <th>timeToClosure</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>153</td>\n      <td>'agramfort'</td>\n      <td>NaN</td>\n      <td>7</td>\n      <td>2010-09-02 14:10:16</td>\n      <td>2</td>\n      <td>9</td>\n      <td>2010-09-01 13:06:00</td>\n      <td>77</td>\n      <td>MDExOlB1bGxSZXF1ZXN0NjU0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>MERGED</td>\n      <td>more on LARS (we're getting there)</td>\n      <td>1 days 01:04:16</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>51</td>\n      <td>'agramfort'</td>\n      <td>this is just a draft but maybe a good start to...</td>\n      <td>2</td>\n      <td>2010-10-23 15:44:33</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2010-09-02 17:13:55</td>\n      <td>0</td>\n      <td>MDExOlB1bGxSZXF1ZXN0MTEzOQ==</td>\n      <td>4</td>\n      <td>0</td>\n      <td>CLOSED</td>\n      <td>Scaling and preprocessing</td>\n      <td>50 days 22:30:38</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>6631</td>\n      <td>'ogrisel'</td>\n      <td>Implementation of CD for elastic net on scipy....</td>\n      <td>13</td>\n      <td>2010-09-14 13:00:43</td>\n      <td>2</td>\n      <td>25</td>\n      <td>2010-09-09 16:03:53</td>\n      <td>9</td>\n      <td>MDExOlB1bGxSZXF1ZXN0MzEzNg==</td>\n      <td>1</td>\n      <td>0</td>\n      <td>MERGED</td>\n      <td>Issue 77 sparse cd</td>\n      <td>4 days 20:56:50</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>105</td>\n      <td>'GaelVaroquaux'</td>\n      <td>Code review: I am interested in suggestions on...</td>\n      <td>6</td>\n      <td>2010-09-16 21:39:45</td>\n      <td>1</td>\n      <td>3</td>\n      <td>2010-09-15 15:48:15</td>\n      <td>27</td>\n      <td>MDExOlB1bGxSZXF1ZXN0NTA0Nw==</td>\n      <td>2</td>\n      <td>0</td>\n      <td>MERGED</td>\n      <td>Work on cross val and pipelines.</td>\n      <td>1 days 05:51:30</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>12636</td>\n      <td>'ogrisel'</td>\n      <td>NaN</td>\n      <td>14</td>\n      <td>2010-10-25 00:27:02</td>\n      <td>1</td>\n      <td>17</td>\n      <td>2010-10-24 15:29:53</td>\n      <td>8</td>\n      <td>MDExOlB1bGxSZXF1ZXN0MTk0NjY=</td>\n      <td>2</td>\n      <td>0</td>\n      <td>CLOSED</td>\n      <td>Some cleanups</td>\n      <td>0 days 08:57:09</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "   additions            author  \\\n0        153       'agramfort'   \n1         51       'agramfort'   \n2       6631         'ogrisel'   \n3        105   'GaelVaroquaux'   \n4      12636         'ogrisel'   \n\n                                            bodyText  changedFiles  \\\n0                                                NaN             7   \n1  this is just a draft but maybe a good start to...             2   \n2  Implementation of CD for elastic net on scipy....            13   \n3  Code review: I am interested in suggestions on...             6   \n4                                                NaN            14   \n\n             closedAt comments commits           createdAt  deletions  \\\n0 2010-09-02 14:10:16        2       9 2010-09-01 13:06:00         77   \n1 2010-10-23 15:44:33        1       1 2010-09-02 17:13:55          0   \n2 2010-09-14 13:00:43        2      25 2010-09-09 16:03:53          9   \n3 2010-09-16 21:39:45        1       3 2010-09-15 15:48:15         27   \n4 2010-10-25 00:27:02        1      17 2010-10-24 15:29:53          8   \n\n                             id participants reactions   state  \\\n0      MDExOlB1bGxSZXF1ZXN0NjU0            3         0  MERGED   \n1  MDExOlB1bGxSZXF1ZXN0MTEzOQ==            4         0  CLOSED   \n2  MDExOlB1bGxSZXF1ZXN0MzEzNg==            1         0  MERGED   \n3  MDExOlB1bGxSZXF1ZXN0NTA0Nw==            2         0  MERGED   \n4  MDExOlB1bGxSZXF1ZXN0MTk0NjY=            2         0  CLOSED   \n\n                                title    timeToClosure  \n0  more on LARS (we're getting there)  1 days 01:04:16  \n1           Scaling and preprocessing 50 days 22:30:38  \n2                  Issue 77 sparse cd  4 days 20:56:50  \n3    Work on cross val and pipelines.  1 days 05:51:30  \n4                       Some cleanups  0 days 08:57:09  "
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Timestamp('2020-02-24 10:41:36.926258')"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "currentTime = pd.Timestamp.now()\n",
    "currentTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Timedelta('-4 days +16:26:35.073742')"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closedAt = df['createdAt'][9340] - currentTime\n",
    "closedAt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0    1 days 01:04:16\n1   50 days 22:30:38\n2    4 days 20:56:50\n3    1 days 05:51:30\n4    0 days 08:57:09\nName: time_to_closure, dtype: timedelta64[ns]"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['time_to_closure'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['repoName'] = 'scikit-learn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0    scikit-learn\n1    scikit-learn\n2    scikit-learn\n3    scikit-learn\n4    scikit-learn\nName: repoName, dtype: object"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['repoName'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SECRET = os.environ.get('SECRET')\n",
    "URL = 'https://github.com/scikit-learn/scikit-learn'\n",
    "DATE_FORMAT = '%Y-%m-%dT%H:%M:%SZ'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repository():\n",
    "    user = 'scikit-learn'\n",
    "    repo = 'scikit-learn'\n",
    "    query = '''\n",
    "    query ($user: String!, $repo: String!){\n",
    "        repository(owner: $user, name: $repo) {\n",
    "                name\n",
    "                owner {\n",
    "                    login\n",
    "                    }\n",
    "                description\n",
    "                primaryLanguage {\n",
    "                    name\n",
    "                    }\n",
    "                stars: stargazers {\n",
    "                    totalCount\n",
    "                    }\n",
    "                forks: forkCount\n",
    "                totalIssues: issues {\n",
    "                    totalCount\n",
    "                    }\n",
    "                openIssues: issues (states: [OPEN]) {\n",
    "                    totalCount\n",
    "                    }\n",
    "                closedIssues: issues (states: [CLOSED]) {\n",
    "                    totalCount\n",
    "                    }\n",
    "                vulnerabilityAlerts {\n",
    "                    totalCount\n",
    "                    }\n",
    "                totalPRs: pullRequests {\n",
    "                    totalCount\n",
    "                    }\n",
    "                openPRs: pullRequests (states: [OPEN]) {\n",
    "                    totalCount\n",
    "                    }\n",
    "                mergedPRs: pullRequests (states: [MERGED]) {\n",
    "                    totalCount\n",
    "                    }\n",
    "                closedPRs: pullRequests (states: [CLOSED]) {\n",
    "                    totalCount\n",
    "                    }\n",
    "                createdAt\n",
    "                updatedAt\n",
    "                diskUsage\n",
    "                pullRequests (last: 50) {\n",
    "                nodes {\n",
    "                    author {\n",
    "                        login\n",
    "                        }\n",
    "                    state\n",
    "                    createdAt\n",
    "                    closedAt\n",
    "                    changedFiles\n",
    "                    additions\n",
    "                    deletions\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        '''\n",
    "\n",
    "    variables = {'user': user, 'repo': repo}\n",
    "    data = runQuery(query, variables).json()['data']['repository']\n",
    "    data['stars'] = data['stars']['totalCount']\n",
    "    data['owner'] = data['owner']['login']\n",
    "    data['primaryLanguage'] = data['primaryLanguage']['name']\n",
    "    data['totalIssues'] = data['totalIssues']['totalCount']\n",
    "    data['openIssues'] = data['openIssues']['totalCount']\n",
    "    data['closedIssues'] = data['closedIssues']['totalCount']\n",
    "    data['totalPRs'] = data['totalPRs']['totalCount']\n",
    "    data['openPRs'] = data['openPRs']['totalCount']\n",
    "    data['mergedPRs'] = data['mergedPRs']['totalCount']\n",
    "    data['closedPRs'] = data['closedPRs']['totalCount']\n",
    "    data['vulnerabilityAlerts'] = data['vulnerabilityAlerts']['totalCount']\n",
    "\n",
    "    data['PRacceptanceRate'] = data['mergedPRs'] / (data['mergedPRs'] +\n",
    "                                                    data['closedPRs'])\n",
    "    data['createdAt'] = datetime.strptime(data['createdAt'],\n",
    "                                        DATE_FORMAT)\n",
    "    data['updatedAt'] = datetime.strptime(data['updatedAt'],\n",
    "                                        DATE_FORMAT)\n",
    "    data['ageInDays'] = (datetime.now().date() -\n",
    "                        data['createdAt'].date()).days\n",
    "    data['starsPerDay'] = data['stars'] / data['ageInDays']\n",
    "    data['forksPerDay'] = data['forks'] / data['ageInDays']\n",
    "    data['PRsPerDay'] = data['totalPRs'] / data['ageInDays']\n",
    "    data['issuesPerDay'] = data['totalIssues'] / data['ageInDays']\n",
    "\n",
    "    pull_requests = data['pullRequests']['nodes']\n",
    "    del data['pullRequests']\n",
    "    df = pd.DataFrame.from_records(pull_requests)\n",
    "    df['author'] = [author.get('login') if author is not None else ''\n",
    "                    for author in df['author']]\n",
    "    df['createdAt'] = pd.to_datetime(df['createdAt'], format=DATE_FORMAT)\n",
    "    df['closedAt'] = pd.to_datetime(df['closedAt'], format=DATE_FORMAT)\n",
    "\n",
    "    data['uniquePRauthors'] = df['author'].nunique()\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runQuery(query, variables):\n",
    "    r = requests.post(URL,\n",
    "                      headers={'Authorization': 'token ' + SECRET, },\n",
    "                      json={'query': query,\n",
    "                            'variables': variables\n",
    "                            })\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-58e8c4ab1258>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrepository\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-10-b38aa6135e66>\u001b[0m in \u001b[0;36mrepository\u001b[1;34m()\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[0mvariables\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'user'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0muser\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'repo'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mrepo\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrunQuery\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'data'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'repository'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'stars'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'stars'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'totalCount'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'owner'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'owner'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'login'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\requests\\models.py\u001b[0m in \u001b[0;36mjson\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    895\u001b[0m                     \u001b[1;31m# used.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    896\u001b[0m                     \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 897\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcomplexjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    898\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\json\\__init__.py\u001b[0m in \u001b[0;36mloads\u001b[1;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    346\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[1;32m--> 348\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    349\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    350\u001b[0m         \u001b[0mcls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\json\\decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    335\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    336\u001b[0m         \"\"\"\n\u001b[1;32m--> 337\u001b[1;33m         \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\json\\decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    353\u001b[0m             \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 355\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Expecting value\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    356\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "data = repository()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-24e9135f5e21>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrunQuery\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'data'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'repository'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\requests\\models.py\u001b[0m in \u001b[0;36mjson\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    895\u001b[0m                     \u001b[1;31m# used.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    896\u001b[0m                     \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 897\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcomplexjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    898\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\json\\__init__.py\u001b[0m in \u001b[0;36mloads\u001b[1;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    346\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[1;32m--> 348\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    349\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    350\u001b[0m         \u001b[0mcls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\json\\decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    335\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    336\u001b[0m         \"\"\"\n\u001b[1;32m--> 337\u001b[1;33m         \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\json\\decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    353\u001b[0m             \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 355\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Expecting value\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    356\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "data = runQuery(query, variables).json()['data']['repository']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['SECRET'] = 'd27e436e87c1ddcc8fcade768de9082bacbb6d12'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = 'scikit-learn'\n",
    "repo = 'scikit-learn'\n",
    "query = '''\n",
    "    query ($user: String!, $repo: String!){\n",
    "        repository(owner: $user, name: $repo) {\n",
    "                name\n",
    "                owner {\n",
    "                    login\n",
    "                    }\n",
    "                description\n",
    "                primaryLanguage {\n",
    "                    name\n",
    "                    }\n",
    "                stars: stargazers {\n",
    "                    totalCount\n",
    "                    }\n",
    "                forks: forkCount\n",
    "                totalIssues: issues {\n",
    "                    totalCount\n",
    "                    }\n",
    "                openIssues: issues (states: [OPEN]) {\n",
    "                    totalCount\n",
    "                    }\n",
    "                closedIssues: issues (states: [CLOSED]) {\n",
    "                    totalCount\n",
    "                    }\n",
    "                vulnerabilityAlerts {\n",
    "                    totalCount\n",
    "                    }\n",
    "                totalPRs: pullRequests {\n",
    "                    totalCount\n",
    "                    }\n",
    "                openPRs: pullRequests (states: [OPEN]) {\n",
    "                    totalCount\n",
    "                    }\n",
    "                mergedPRs: pullRequests (states: [MERGED]) {\n",
    "                    totalCount\n",
    "                    }\n",
    "                closedPRs: pullRequests (states: [CLOSED]) {\n",
    "                    totalCount\n",
    "                    }\n",
    "                createdAt\n",
    "                updatedAt\n",
    "                diskUsage\n",
    "                pullRequests (last: 50) {\n",
    "                nodes {\n",
    "                    author {\n",
    "                        login\n",
    "                        }\n",
    "                    state\n",
    "                    createdAt\n",
    "                    closedAt\n",
    "                    changedFiles\n",
    "                    additions\n",
    "                    deletions\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        '''\n",
    "variables = {'user': user, 'repo': repo}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "column corresponding to pos\n     |  \n     |  Method resolution order:\n     |      JSONDecodeError\n     |      builtins.ValueError\n     |      builtins.Exception\n     |      builtins.BaseException\n     |      builtins.object\n     |  \n     |  Methods defined here:\n     |  \n     |  __init__(self, msg, doc, pos)\n     |      Initialize self.  See help(type(self)) for accurate signature.\n     |  \n     |  __reduce__(self)\n     |      Helper for pickle.\n     |  \n     |  ----------------------------------------------------------------------\n     |  Data descriptors defined here:\n     |  \n     |  __weakref__\n     |      list of weak references to the object (if defined)\n     |  \n     |  ----------------------------------------------------------------------\n     |  Static methods inherited from builtins.ValueError:\n     |  \n     |  __new__(*args, **kwargs) from builtins.type\n     |      Create and return a new object.  See help(type) for accurate signature.\n     |  \n     |  ----------------------------------------------------------------------\n     |  Methods inherited from builtins.BaseException:\n     |  \n     |  __delattr__(self, name, /)\n     |      Implement delattr(self, name).\n     |  \n     |  __getattribute__(self, name, /)\n     |      Return getattr(self, name).\n     |  \n     |  __repr__(self, /)\n     |      Return repr(self).\n     |  \n     |  __setattr__(self, name, value, /)\n     |      Implement setattr(self, name, value).\n     |  \n     |  __setstate__(...)\n     |  \n     |  __str__(self, /)\n     |      Return str(self).\n     |  \n     |  with_traceback(...)\n     |      Exception.with_traceback(tb) --\n     |      set self.__traceback__ to tb and return self.\n     |  \n     |  ----------------------------------------------------------------------\n     |  Data descriptors inherited from builtins.BaseException:\n     |  \n     |  __cause__\n     |      exception cause\n     |  \n     |  __context__\n     |      exception context\n     |  \n     |  __dict__\n     |  \n     |  __suppress_context__\n     |  \n     |  __traceback__\n     |  \n     |  args\n    \n    class JSONDecoder(builtins.object)\n     |  JSONDecoder(*, object_hook=None, parse_float=None, parse_int=None, parse_constant=None, strict=True, object_pairs_hook=None)\n     |  \n     |  Simple JSON <http://json.org> decoder\n     |  \n     |  Performs the following translations in decoding by default:\n     |  \n     |  +---------------+-------------------+\n     |  | JSON          | Python            |\n     |  +===============+===================+\n     |  | object        | dict              |\n     |  +---------------+-------------------+\n     |  | array         | list              |\n     |  +---------------+-------------------+\n     |  | string        | str               |\n     |  +---------------+-------------------+\n     |  | number (int)  | int               |\n     |  +---------------+-------------------+\n     |  | number (real) | float             |\n     |  +---------------+-------------------+\n     |  | true          | True              |\n     |  +---------------+-------------------+\n     |  | false         | False             |\n     |  +---------------+-------------------+\n     |  | null          | None              |\n     |  +---------------+-------------------+\n     |  \n     |  It also understands ``NaN``, ``Infinity``, and ``-Infinity`` as\n     |  their corresponding ``float`` values, which is outside the JSON spec.\n     |  \n     |  Methods defined here:\n     |  \n     |  __init__(self, *, object_hook=None, parse_float=None, parse_int=None, parse_constant=None, strict=True, object_pairs_hook=None)\n     |      ``object_hook``, if specified, will be called with the result\n     |      of every JSON object decoded and its return value will be used in\n     |      place of the given ``dict``.  This can be used to provide custom\n     |      deserializations (e.g. to support JSON-RPC class hinting).\n     |      \n     |      ``object_pairs_hook``, if specified will be called with the result of\n     |      every JSON object decoded with an ordered list of pairs.  The return\n     |      value of ``object_pairs_hook`` will be used instead of the ``dict``.\n     |      This feature can be used to implement custom decoders.\n     |      If ``object_hook`` is also defined, the ``object_pairs_hook`` takes\n     |      priority.\n     |      \n     |      ``parse_float``, if specified, will be called with the string\n     |      of every JSON float to be decoded. By default this is equivalent to\n     |      float(num_str). This can be used to use another datatype or parser\n     |      for JSON floats (e.g. decimal.Decimal).\n     |      \n     |      ``parse_int``, if specified, will be called with the string\n     |      of every JSON int to be decoded. By default this is equivalent to\n     |      int(num_str). This can be used to use another datatype or parser\n     |      for JSON integers (e.g. float).\n     |      \n     |      ``parse_constant``, if specified, will be called with one of the\n     |      following strings: -Infinity, Infinity, NaN.\n     |      This can be used to raise an exception if invalid JSON numbers\n     |      are encountered.\n     |      \n     |      If ``strict`` is false (true is the default), then control\n     |      characters will be allowed inside strings.  Control characters in\n     |      this context are those with character codes in the 0-31 range,\n     |      including ``'\\t'`` (tab), ``'\\n'``, ``'\\r'`` and ``'\\0'``.\n     |  \n     |  decode(self, s, _w=<built-in method match of re.Pattern object at 0x0000018AA462BDB0>)\n     |      Return the Python representation of ``s`` (a ``str`` instance\n     |      containing a JSON document).\n     |  \n     |  raw_decode(self, s, idx=0)\n     |      Decode a JSON document from ``s`` (a ``str`` beginning with\n     |      a JSON document) and return a 2-tuple of the Python\n     |      representation and the index in ``s`` where the document ended.\n     |      \n     |      This can be used to decode a JSON document from a string that may\n     |      have extraneous data at the end.\n     |  \n     |  ----------------------------------------------------------------------\n     |  Data descriptors defined here:\n     |  \n     |  __dict__\n     |      dictionary for instance variables (if defined)\n     |  \n     |  __weakref__\n     |      list of weak references to the object (if defined)\n    \n    class JSONEncoder(builtins.object)\n     |  JSONEncoder(*, skipkeys=False, ensure_ascii=True, check_circular=True, allow_nan=True, sort_keys=False, indent=None, separators=None, default=None)\n     |  \n     |  Extensible JSON <http://json.org> encoder for Python data structures.\n     |  \n     |  Supports the following objects and types by default:\n     |  \n     |  +-------------------+---------------+\n     |  | Python            | JSON          |\n     |  +===================+===============+\n     |  | dict              | object        |\n     |  +-------------------+---------------+\n     |  | list, tuple       | array         |\n     |  +-------------------+---------------+\n     |  | str               | string        |\n     |  +-------------------+---------------+\n     |  | int, float        | number        |\n     |  +-------------------+---------------+\n     |  | True              | true          |\n     |  +-------------------+---------------+\n     |  | False             | false         |\n     |  +-------------------+---------------+\n     |  | None              | null          |\n     |  +-------------------+---------------+\n     |  \n     |  To extend this to recognize other objects, subclass and implement a\n     |  ``.default()`` method with another method that returns a serializable\n     |  object for ``o`` if possible, otherwise it should call the superclass\n     |  implementation (to raise ``TypeError``).\n     |  \n     |  Methods defined here:\n     |  \n     |  __init__(self, *, skipkeys=False, ensure_ascii=True, check_circular=True, allow_nan=True, sort_keys=False, indent=None, separators=None, default=None)\n     |      Constructor for JSONEncoder, with sensible defaults.\n     |      \n     |      If skipkeys is false, then it is a TypeError to attempt\n     |      encoding of keys that are not str, int, float or None.  If\n     |      skipkeys is True, such items are simply skipped.\n     |      \n     |      If ensure_ascii is true, the output is guaranteed to be str\n     |      objects with all incoming non-ASCII characters escaped.  If\n     |      ensure_ascii is false, the output can contain non-ASCII characters.\n     |      \n     |      If check_circular is true, then lists, dicts, and custom encoded\n     |      objects will be checked for circular references during encoding to\n     |      prevent an infinite recursion (which would cause an OverflowError).\n     |      Otherwise, no such check takes place.\n     |      \n     |      If allow_nan is true, then NaN, Infinity, and -Infinity will be\n     |      encoded as such.  This behavior is not JSON specification compliant,\n     |      but is consistent with most JavaScript based encoders and decoders.\n     |      Otherwise, it will be a ValueError to encode such floats.\n     |      \n     |      If sort_keys is true, then the output of dictionaries will be\n     |      sorted by key; this is useful for regression tests to ensure\n     |      that JSON serializations can be compared on a day-to-day basis.\n     |      \n     |      If indent is a non-negative integer, then JSON array\n     |      elements and object members will be pretty-printed with that\n     |      indent level.  An indent level of 0 will only insert newlines.\n     |      None is the most compact representation.\n     |      \n     |      If specified, separators should be an (item_separator, key_separator)\n     |      tuple.  The default is (', ', ': ') if *indent* is ``None`` and\n     |      (',', ': ') otherwise.  To get the most compact JSON representation,\n     |      you should specify (',', ':') to eliminate whitespace.\n     |      \n     |      If specified, default is a function that gets called for objects\n     |      that can't otherwise be serialized.  It should return a JSON encodable\n     |      version of the object or raise a ``TypeError``.\n     |  \n     |  default(self, o)\n     |      Implement this method in a subclass such that it returns\n     |      a serializable object for ``o``, or calls the base implementation\n     |      (to raise a ``TypeError``).\n     |      \n     |      For example, to support arbitrary iterators, you could\n     |      implement default like this::\n     |      \n     |          def default(self, o):\n     |              try:\n     |                  iterable = iter(o)\n     |              except TypeError:\n     |                  pass\n     |              else:\n     |                  return list(iterable)\n     |              # Let the base class default method raise the TypeError\n     |              return JSONEncoder.default(self, o)\n     |  \n     |  encode(self, o)\n     |      Return a JSON string representation of a Python data structure.\n     |      \n     |      >>> from json.encoder import JSONEncoder\n     |      >>> JSONEncoder().encode({\"foo\": [\"bar\", \"baz\"]})\n     |      '{\"foo\": [\"bar\", \"baz\"]}'\n     |  \n     |  iterencode(self, o, _one_shot=False)\n     |      Encode the given object and yield each string\n     |      representation as available.\n     |      \n     |      For example::\n     |      \n     |          for chunk in JSONEncoder().iterencode(bigobject):\n     |              mysocket.write(chunk)\n     |  \n     |  ----------------------------------------------------------------------\n     |  Data descriptors defined here:\n     |  \n     |  __dict__\n     |      dictionary for instance variables (if defined)\n     |  \n     |  __weakref__\n     |      list of weak references to the object (if defined)\n     |  \n     |  ----------------------------------------------------------------------\n     |  Data and other attributes defined here:\n     |  \n     |  item_separator = ', '\n     |  \n     |  key_separator = ': '\n\nFUNCTIONS\n    dump(obj, fp, *, skipkeys=False, ensure_ascii=True, check_circular=True, allow_nan=True, cls=None, indent=None, separators=None, default=None, sort_keys=False, **kw)\n        Serialize ``obj`` as a JSON formatted stream to ``fp`` (a\n        ``.write()``-supporting file-like object).\n        \n        If ``skipkeys`` is true then ``dict`` keys that are not basic types\n        (``str``, ``int``, ``float``, ``bool``, ``None``) will be skipped\n        instead of raising a ``TypeError``.\n        \n        If ``ensure_ascii`` is false, then the strings written to ``fp`` can\n        contain non-ASCII characters if they appear in strings contained in\n        ``obj``. Otherwise, all such characters are escaped in JSON strings.\n        \n        If ``check_circular`` is false, then the circular reference check\n        for container types will be skipped and a circular reference will\n        result in an ``OverflowError`` (or worse).\n        \n        If ``allow_nan`` is false, then it will be a ``ValueError`` to\n        serialize out of range ``float`` values (``nan``, ``inf``, ``-inf``)\n        in strict compliance of the JSON specification, instead of using the\n        JavaScript equivalents (``NaN``, ``Infinity``, ``-Infinity``).\n        \n        If ``indent`` is a non-negative integer, then JSON array elements and\n        object members will be pretty-printed with that indent level. An indent\n        level of 0 will only insert newlines. ``None`` is the most compact\n        representation.\n        \n        If specified, ``separators`` should be an ``(item_separator, key_separator)``\n        tuple.  The default is ``(', ', ': ')`` if *indent* is ``None`` and\n        ``(',', ': ')`` otherwise.  To get the most compact JSON representation,\n        you should specify ``(',', ':')`` to eliminate whitespace.\n        \n        ``default(obj)`` is a function that should return a serializable version\n        of obj or raise TypeError. The default simply raises TypeError.\n        \n        If *sort_keys* is true (default: ``False``), then the output of\n        dictionaries will be sorted by key.\n        \n        To use a custom ``JSONEncoder`` subclass (e.g. one that overrides the\n        ``.default()`` method to serialize additional types), specify it with\n        the ``cls`` kwarg; otherwise ``JSONEncoder`` is used.\n    \n    dumps(obj, *, skipkeys=False, ensure_ascii=True, check_circular=True, allow_nan=True, cls=None, indent=None, separators=None, default=None, sort_keys=False, **kw)\n        Serialize ``obj`` to a JSON formatted ``str``.\n        \n        If ``skipkeys`` is true then ``dict`` keys that are not basic types\n        (``str``, ``int``, ``float``, ``bool``, ``None``) will be skipped\n        instead of raising a ``TypeError``.\n        \n        If ``ensure_ascii`` is false, then the return value can contain non-ASCII\n        characters if they appear in strings contained in ``obj``. Otherwise, all\n        such characters are escaped in JSON strings.\n        \n        If ``check_circular`` is false, then the circular reference check\n        for container types will be skipped and a circular reference will\n        result in an ``OverflowError`` (or worse).\n        \n        If ``allow_nan`` is false, then it will be a ``ValueError`` to\n        serialize out of range ``float`` values (``nan``, ``inf``, ``-inf``) in\n        strict compliance of the JSON specification, instead of using the\n        JavaScript equivalents (``NaN``, ``Infinity``, ``-Infinity``).\n        \n        If ``indent`` is a non-negative integer, then JSON array elements and\n        object members will be pretty-printed with that indent level. An indent\n        level of 0 will only insert newlines. ``None`` is the most compact\n        representation.\n        \n        If specified, ``separators`` should be an ``(item_separator, key_separator)``\n        tuple.  The default is ``(', ', ': ')`` if *indent* is ``None`` and\n        ``(',', ': ')`` otherwise.  To get the most compact JSON representation,\n        you should specify ``(',', ':')`` to eliminate whitespace.\n        \n        ``default(obj)`` is a function that should return a serializable version\n        of obj or raise TypeError. The default simply raises TypeError.\n        \n        If *sort_keys* is true (default: ``False``), then the output of\n        dictionaries will be sorted by key.\n        \n        To use a custom ``JSONEncoder`` subclass (e.g. one that overrides the\n        ``.default()`` method to serialize additional types), specify it with\n        the ``cls`` kwarg; otherwise ``JSONEncoder`` is used.\n    \n    load(fp, *, cls=None, object_hook=None, parse_float=None, parse_int=None, parse_constant=None, object_pairs_hook=None, **kw)\n        Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\n        a JSON document) to a Python object.\n        \n        ``object_hook`` is an optional function that will be called with the\n        result of any object literal decode (a ``dict``). The return value of\n        ``object_hook`` will be used instead of the ``dict``. This feature\n        can be used to implement custom decoders (e.g. JSON-RPC class hinting).\n        \n        ``object_pairs_hook`` is an optional function that will be called with the\n        result of any object literal decoded with an ordered list of pairs.  The\n        return value of ``object_pairs_hook`` will be used instead of the ``dict``.\n        This feature can be used to implement custom decoders.  If ``object_hook``\n        is also defined, the ``object_pairs_hook`` takes priority.\n        \n        To use a custom ``JSONDecoder`` subclass, specify it with the ``cls``\n        kwarg; otherwise ``JSONDecoder`` is used.\n    \n    loads(s, *, encoding=None, cls=None, object_hook=None, parse_float=None, parse_int=None, parse_constant=None, object_pairs_hook=None, **kw)\n        Deserialize ``s`` (a ``str``, ``bytes`` or ``bytearray`` instance\n        containing a JSON document) to a Python object.\n        \n        ``object_hook`` is an optional function that will be called with the\n        result of any object literal decode (a ``dict``). The return value of\n        ``object_hook`` will be used instead of the ``dict``. This feature\n        can be used to implement custom decoders (e.g. JSON-RPC class hinting).\n        \n        ``object_pairs_hook`` is an optional function that will be called with the\n        result of any object literal decoded with an ordered list of pairs.  The\n        return value of ``object_pairs_hook`` will be used instead of the ``dict``.\n        This feature can be used to implement custom decoders.  If ``object_hook``\n        is also defined, the ``object_pairs_hook`` takes priority.\n        \n        ``parse_float``, if specified, will be called with the string\n        of every JSON float to be decoded. By default this is equivalent to\n        float(num_str). This can be used to use another datatype or parser\n        for JSON floats (e.g. decimal.Decimal).\n        \n        ``parse_int``, if specified, will be called with the string\n        of every JSON int to be decoded. By default this is equivalent to\n        int(num_str). This can be used to use another datatype or parser\n        for JSON integers (e.g. float).\n        \n        ``parse_constant``, if specified, will be called with one of the\n        following strings: -Infinity, Infinity, NaN.\n        This can be used to raise an exception if invalid JSON numbers\n        are encountered.\n        \n        To use a custom ``JSONDecoder`` subclass, specify it with the ``cls``\n        kwarg; otherwise ``JSONDecoder`` is used.\n        \n        The ``encoding`` argument is ignored and deprecated.\n\nDATA\n    __all__ = ['dump', 'dumps', 'load', 'loads', 'JSONDecoder', 'JSONDecod...\n\nVERSION\n    2.0.9\n\nAUTHOR\n    Bob Ippolito <bob@redivi.com>\n\nFILE\n    c:\\programdata\\anaconda3\\lib\\json\\__init__.py\n\n\n"
    }
   ],
   "source": [
    "help(json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'json' has no attribute 'agent'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-433a575df285>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'agent'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: module 'json' has no attribute 'agent'"
     ]
    }
   ],
   "source": [
    "json."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}